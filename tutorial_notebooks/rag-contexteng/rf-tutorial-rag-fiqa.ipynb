{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06d0c6d",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/RapidFire - Blue bug -white text.svg\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/6vSTtncKNN\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/discord-button.svg\" width=\"145\"></a>\n",
    "<a href=\"https://oss-docs.rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/documentation-button.svg\" width=\"125\"></a>\n",
    "<br/>\n",
    "Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/RapidFireAI/rapidfireai\">GitHub</a></i> ‚≠ê\n",
    "<br/>\n",
    "To install RapidFire AI on your own machine, see the <a href=\"https://oss-docs.rapidfire.ai/en/latest/walkthrough.html\">Install and Get Started</a> guide in our docs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fc36b",
   "metadata": {},
   "source": [
    "### RapidFire AI RAG/Context Engineering Tutorial Use Case: Financial Opinion Q&A Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8598e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfireai import Experiment\n",
    "from rapidfireai.evals.automl import List, RFLangChainRagSpec, RFvLLMModelConfig, RFPromptManager, RFGridSearch\n",
    "import re, json\n",
    "from typing import List as listtype, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16327b",
   "metadata": {},
   "source": [
    "### Load Dataset and Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee571098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset directory is now in tutorial_notebooks/evals/datasets\n",
    "dataset_dir = Path(\"datasets\")\n",
    "\n",
    "fiqa_dataset = load_dataset(\"json\", data_files=str(dataset_dir / \"fiqa\" / \"queries.jsonl\"), split=\"train\")\n",
    "fiqa_dataset = fiqa_dataset.rename_columns({\"text\": \"query\", \"_id\": \"query_id\"})\n",
    "qrels = pd.read_csv(str(dataset_dir / \"fiqa\" / \"qrels.tsv\"), sep=\"\\t\")\n",
    "qrels = qrels.rename(\n",
    "    columns={\"query-id\": \"query_id\", \"corpus-id\": \"corpus_id\", \"score\": \"relevance\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28399289",
   "metadata": {},
   "source": [
    "### Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70816920",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(experiment_name=\"exp1-fiqa-rag\", mode=\"evals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a21ee",
   "metadata": {},
   "source": [
    "### Define Partial Multi-Config Knobs for LangChain part of RAG Pipeline using RapidFire AI Wrapper APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b73586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# Per-Actor batch size for hardware efficiency\n",
    "batch_size = 128\n",
    "\n",
    "# 2 chunk sizes x 2 reranking top-n = 4 combinations in total\n",
    "rag_gpu = RFLangChainRagSpec(\n",
    "    document_loader=DirectoryLoader(\n",
    "        path=str(dataset_dir / \"fiqa\"),\n",
    "        glob=\"corpus.jsonl\",\n",
    "        loader_cls=JSONLoader,\n",
    "        loader_kwargs={\n",
    "            \"jq_schema\": \".\",\n",
    "            \"content_key\": \"text\",\n",
    "            \"metadata_func\": lambda record, metadata: {\n",
    "                \"corpus_id\": int(record.get(\"_id\"))\n",
    "            },  # store the document id\n",
    "            \"json_lines\": True,\n",
    "            \"text_content\": False,\n",
    "        },\n",
    "        sample_seed=42,\n",
    "    ),\n",
    "    # 2 chunking strategies with different chunk sizes\n",
    "    text_splitter=List([\n",
    "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                encoding_name=\"gpt2\", chunk_size=256, chunk_overlap=32\n",
    "            ),\n",
    "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                encoding_name=\"gpt2\", chunk_size=128, chunk_overlap=32\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    embedding_cls=HuggingFaceEmbeddings,\n",
    "    embedding_kwargs={\n",
    "        \"model_name\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"model_kwargs\": {\"device\": \"cuda:0\"},\n",
    "        \"encode_kwargs\": {\"normalize_embeddings\": True, \"batch_size\": batch_size},\n",
    "    },\n",
    "    vector_store=None,  # uses FAISS by default\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 15},\n",
    "    # 2 reranking strategies with different top-n values\n",
    "    reranker_cls=CrossEncoderReranker,\n",
    "    reranker_kwargs={\n",
    "        \"model_name\": \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n",
    "        \"model_kwargs\": {\"device\": \"cuda:0\"},\n",
    "        \"top_n\": List([2, 5]),\n",
    "    },\n",
    "    enable_gpu_search=True,  # GPU-based exact search instead of ANN index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fb0a8",
   "metadata": {},
   "source": [
    "### Define Data Processing and Postprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc17276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_preprocess_fn(\n",
    "    batch: Dict[str, listtype], rag: RFLangChainRagSpec, prompt_manager: RFPromptManager\n",
    ") -> Dict[str, listtype]:\n",
    "    \"\"\"Function to prepare the final inputs given to the generator model\"\"\"\n",
    "\n",
    "    INSTRUCTIONS = \"Utilize your financial knowledge, give your answer or opinion to the input question or subject matter.\"\n",
    "\n",
    "    # Perform batched retrieval over all queries; returns a list of lists of k documents per query\n",
    "    all_context = rag.get_context(batch_queries=batch[\"query\"], serialize=False)\n",
    "\n",
    "    # Extract the retrieved document ids from the context\n",
    "    retrieved_documents = [\n",
    "        [doc.metadata[\"corpus_id\"] for doc in docs] for docs in all_context\n",
    "    ]\n",
    "\n",
    "    # Serialize the retrieved documents into a single string per query using the default template\n",
    "    serialized_context = rag.serialize_documents(all_context)\n",
    "    batch[\"query_id\"] = [int(query_id) for query_id in batch[\"query_id\"]]\n",
    "\n",
    "    # Each batch to contain conversational prompt, retrieved documents, and original 'query_id', 'query', 'metadata'\n",
    "    return {\n",
    "        \"prompts\": [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": INSTRUCTIONS},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Here is some relevant context:\\n{context}. \\nNow answer the following question using the context provided earlier:\\n{question}\",\n",
    "                },\n",
    "            ]\n",
    "            for question, context in zip(batch[\"query\"], serialized_context)\n",
    "        ],\n",
    "        \"retrieved_documents\": retrieved_documents,\n",
    "        **batch,\n",
    "    }\n",
    "\n",
    "\n",
    "def sample_postprocess_fn(batch: Dict[str, listtype]) -> Dict[str, listtype]:\n",
    "    \"\"\"Function to postprocess outputs produced by generator model\"\"\"\n",
    "    # Get ground truth documents for each query; can be done in preprocess_fn too but done here for clarity\n",
    "    batch[\"ground_truth_documents\"] = [\n",
    "        qrels[qrels[\"query_id\"] == query_id][\"corpus_id\"].tolist()\n",
    "        for query_id in batch[\"query_id\"]\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb16c3",
   "metadata": {},
   "source": [
    "### Define Custom Eval Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22773d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def compute_ndcg_at_k(retrieved_docs: set, expected_docs: set, k=5):\n",
    "    \"\"\"Utility function to compute NDCG@k\"\"\"\n",
    "    relevance = [1 if doc in expected_docs else 0 for doc in list(retrieved_docs)[:k]]\n",
    "    dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(relevance))\n",
    "\n",
    "    # IDCG: perfect ranking limited by min(k, len(expected_docs))\n",
    "    ideal_length = min(k, len(expected_docs))\n",
    "    ideal_relevance = [3] * ideal_length + [0] * (k - ideal_length)\n",
    "    idcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(ideal_relevance))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_rr(retrieved_docs: set, expected_docs: set):\n",
    "    \"\"\"Utility function to compute Reciprocal Rank (RR) for a single query\"\"\"\n",
    "    rr = 0\n",
    "    for i, retrieved_doc in enumerate(retrieved_docs):\n",
    "        if retrieved_doc in expected_docs:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "    return rr\n",
    "\n",
    "\n",
    "def sample_compute_metrics_fn(batch: Dict[str, listtype]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Function to compute all eval metrics based on retrievals and/or generations\"\"\"\n",
    "\n",
    "    true_positives, precisions, recalls, f1_scores, ndcgs, rrs = 0, [], [], [], [], []\n",
    "    total_queries = len(batch[\"query\"])\n",
    "\n",
    "    for pred, gt in zip(batch[\"retrieved_documents\"], batch[\"ground_truth_documents\"]):\n",
    "        expected_set = set(gt)\n",
    "        retrieved_set = set(pred)\n",
    "\n",
    "        true_positives = len(expected_set.intersection(retrieved_set))\n",
    "        precision = true_positives / len(retrieved_set) if len(retrieved_set) > 0 else 0\n",
    "        recall = true_positives / len(expected_set) if len(expected_set) > 0 else 0\n",
    "        f1 = (\n",
    "            2 * precision * recall / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        ndcgs.append(compute_ndcg_at_k(retrieved_set, expected_set, k=5))\n",
    "        rrs.append(compute_rr(retrieved_set, expected_set))\n",
    "\n",
    "    return {\n",
    "        \"Total\": {\"value\": total_queries},\n",
    "        \"Precision\": {\"value\": sum(precisions) / total_queries},\n",
    "        \"Recall\": {\"value\": sum(recalls) / total_queries},\n",
    "        \"F1 Score\": {\"value\": sum(f1_scores) / total_queries},\n",
    "        \"NDCG@5\": {\"value\": sum(ndcgs) / total_queries},\n",
    "        \"MRR\": {\"value\": sum(rrs) / total_queries},\n",
    "    }\n",
    "\n",
    "\n",
    "def sample_accumulate_metrics_fn(\n",
    "    aggregated_metrics: Dict[str, listtype],\n",
    ") -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Function to accumulate eval metrics across all batches\"\"\"\n",
    "\n",
    "    num_queries_per_batch = [m[\"value\"] for m in aggregated_metrics[\"Total\"]]\n",
    "    total_queries = sum(num_queries_per_batch)\n",
    "    algebraic_metrics = [\"Precision\", \"Recall\", \"F1 Score\", \"NDCG@5\", \"MRR\"]\n",
    "\n",
    "    return {\n",
    "        \"Total\": {\"value\": total_queries},\n",
    "        **{\n",
    "            metric: {\n",
    "                \"value\": sum(\n",
    "                    m[\"value\"] * queries\n",
    "                    for m, queries in zip(\n",
    "                        aggregated_metrics[metric], num_queries_per_batch\n",
    "                    )\n",
    "                )\n",
    "                / total_queries,\n",
    "                \"is_algebraic\": True,\n",
    "                \"value_range\": (0, 1),\n",
    "            }\n",
    "            for metric in algebraic_metrics\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57887bc",
   "metadata": {},
   "source": [
    "### Define Partial Multi-Config Knobs for vLLM Generator part of RAG Pipeline using RapidFire AI Wrapper APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 vLLM generator configs with different sizes of generator models\n",
    "\n",
    "vllm_config1 = RFvLLMModelConfig(\n",
    "    model_config={\n",
    "        \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "        \"dtype\": \"half\",\n",
    "        \"gpu_memory_utilization\": 0.7,\n",
    "        \"tensor_parallel_size\": 1,\n",
    "        \"distributed_executor_backend\": \"mp\",\n",
    "        \"enable_chunked_prefill\": False,\n",
    "        \"enable_prefix_caching\": True,\n",
    "        \"max_model_len\": 2048,\n",
    "        \"disable_log_stats\": True,  # Disable vLLM progress logging\n",
    "    },\n",
    "    sampling_params={\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 512,\n",
    "    },\n",
    "    rag=rag_gpu,\n",
    "    prompt_manager=None,\n",
    ")\n",
    "\n",
    "vllm_config2 = RFvLLMModelConfig(\n",
    "    model_config={\n",
    "        \"model\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \"dtype\": \"half\",\n",
    "        \"gpu_memory_utilization\": 0.7,\n",
    "        \"tensor_parallel_size\": 1,\n",
    "        \"distributed_executor_backend\": \"mp\",\n",
    "        \"enable_chunked_prefill\": False,\n",
    "        \"enable_prefix_caching\": True,\n",
    "        \"max_model_len\": 2048,\n",
    "        \"disable_log_stats\": True,  # Disable vLLM progress logging\n",
    "    },\n",
    "    sampling_params={\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 512,\n",
    "    },\n",
    "    rag=rag_gpu,\n",
    "    prompt_manager=None,\n",
    ")\n",
    "\n",
    "config_set = {\n",
    "    \"vllm_config\": List([vllm_config1, vllm_config2]),  # Each represents 4 configs\n",
    "    \"batch_size\": batch_size,\n",
    "    \"preprocess_fn\": sample_preprocess_fn,\n",
    "    \"postprocess_fn\": sample_postprocess_fn,\n",
    "    \"compute_metrics_fn\": sample_compute_metrics_fn,\n",
    "    \"accumulate_metrics_fn\": sample_accumulate_metrics_fn,\n",
    "    \"online_strategy_kwargs\": {\n",
    "        \"strategy_name\": \"normal\",\n",
    "        \"confidence_level\": 0.95,\n",
    "        \"use_fpc\": True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7dd280",
   "metadata": {},
   "source": [
    "### Create Config Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f26d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid search across all sets of config knob values = 8 combinations in total\n",
    "config_group = RFGridSearch(config_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa186134",
   "metadata": {},
   "source": [
    "### Run Multi-Config Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch evals of all RAG configs in the config_group with swap granularity of 4 chunks\n",
    "# NB: If your machine has only 1 GPUs, set num_actors=1\n",
    "results = experiment.run_evals(\n",
    "    config_group=config_group,\n",
    "    dataset=fiqa_dataset,\n",
    "    num_actors=2,\n",
    "    num_shards=4,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ce33b",
   "metadata": {},
   "source": [
    "### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results dict to DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {k: v['value'] if isinstance(v, dict) and 'value' in v else v for k, v in {**metrics_dict, 'run_id': run_id}.items()}\n",
    "    for run_id, (_, metrics_dict) in results.items()\n",
    "])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135d951",
   "metadata": {},
   "source": [
    "### End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09265e66",
   "metadata": {},
   "source": [
    "### View RapidFire AI Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05379a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the experiment-specific log file\n",
    "log_file = experiment.get_log_file_path()\n",
    "\n",
    "print(f\"üìÑ Log File: {log_file}\")\n",
    "print()\n",
    "\n",
    "if log_file.exists():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Last 30 lines of {log_file.name}:\")\n",
    "    print(\"=\" * 80)\n",
    "    with open(log_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-30:]:\n",
    "            print(line.rstrip())\n",
    "else:\n",
    "    print(f\"‚ùå Log file not found: {log_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
