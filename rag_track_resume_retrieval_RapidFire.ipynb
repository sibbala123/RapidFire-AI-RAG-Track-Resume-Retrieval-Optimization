{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# RapidFire AI â€” RAG Track Notebook (Resume Retrieval)\\n\n",
                "\\n\n",
                "End-to-end: Load dataset -> Define configurations -> Evaluate retrieval metrics\\n\n",
                "\\n\n",
                "**Dataset layout:**\\n\n",
                "```\\n\n",
                "dataset/\\n\n",
                "  corpus.jsonl\\n\n",
                "  queries.jsonl\\n\n",
                "  qrels.tsv\\n\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "install",
            "metadata": {},
            "source": [
                "## 0) Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "pip_install",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "!{sys.executable} -m pip install -q datasets pandas langchain langchain-community langchain-huggingface langchain-text-splitters beautifulsoup4 sentence-transformers scikit-learn tiktoken faiss-cpu lxml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "19a292a5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting tf-keras\n",
                        "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
                        "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tf-keras) (2.20.0)\n",
                        "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
                        "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
                        "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.9.23)\n",
                        "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
                        "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
                        "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
                        "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
                        "Requirement already satisfied: packaging in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
                        "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.32.1)\n",
                        "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
                        "Requirement already satisfied: setuptools in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
                        "Requirement already satisfied: six>=1.12.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
                        "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.2.0)\n",
                        "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\n",
                        "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.0.0)\n",
                        "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.75.1)\n",
                        "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
                        "Requirement already satisfied: keras>=3.10.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.0)\n",
                        "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.3)\n",
                        "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
                        "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.11)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.10.5)\n",
                        "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
                        "Requirement already satisfied: pillow in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
                        "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
                        "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
                        "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
                        "Requirement already satisfied: rich in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.2.0)\n",
                        "Requirement already satisfied: namex in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
                        "Requirement already satisfied: optree in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
                        "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
                        "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jayan\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
                        "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
                        "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
                        "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
                        "   ------------------------------------- -- 1.6/1.7 MB 16.8 MB/s eta 0:00:01\n",
                        "   ---------------------------------------- 1.7/1.7 MB 11.5 MB/s  0:00:00\n",
                        "Installing collected packages: tf-keras\n",
                        "Successfully installed tf-keras-2.20.1\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "!{sys.executable} -m pip install tf-keras"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "imports",
            "metadata": {},
            "source": [
                "## 1) Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "basic_imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import json\n",
                "import math\n",
                "import random\n",
                "from pathlib import Path\n",
                "from typing import Dict, Any, List as PyList, Optional\n",
                "import pandas as pd\n",
                "from datasets import load_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "langchain_imports",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\jayan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from langchain_huggingface import HuggingFaceEmbeddings\n",
                "from langchain_core.documents import Document\n",
                "from langchain_community.vectorstores import FAISS\n",
                "from bs4 import BeautifulSoup"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dataset_section",
            "metadata": {},
            "source": [
                "## 2) Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "dataset_paths",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "dataset_dir = Path(\"dataset\")\n",
                "\n",
                "assert (dataset_dir / \"corpus.jsonl\").exists(), f\"Missing: {dataset_dir / 'corpus.jsonl'}\"\n",
                "assert (dataset_dir / \"queries.jsonl\").exists(), f\"Missing: {dataset_dir / 'queries.jsonl'}\"\n",
                "assert (dataset_dir / \"qrels.tsv\").exists(), f\"Missing: {dataset_dir / 'qrels.tsv'}\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "load_queries",
            "metadata": {},
            "outputs": [],
            "source": [
                "queries_ds = load_dataset(\n",
                "    \"json\",\n",
                "    data_files=str(dataset_dir / \"queries.jsonl\"),\n",
                "    split=\"train\"\n",
                ")\n",
                "\n",
                "# This rename does nothing (same names), so it's safe to remove\n",
                "# queries_ds = queries_ds.rename_columns({\"query\": \"query\", \"query_id\": \"query_id\"})\n",
                "\n",
                "queries_ds = queries_ds.map(lambda x: {\"query_id\": int(x[\"query_id\"])})\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "load_qrels",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 15 queries and 594 relevance judgments\n"
                    ]
                }
            ],
            "source": [
                "qrels = pd.read_csv(dataset_dir / \"qrels.tsv\", sep=\"\\t\")\n",
                "\n",
                "qrels = qrels.rename(\n",
                "    columns={\n",
                "        \"query-id\": \"query_id\",\n",
                "        \"corpus-id\": \"corpus_id\",\n",
                "        \"score\": \"relevance\",\n",
                "    }\n",
                ")\n",
                "\n",
                "qrels[\"query_id\"] = qrels[\"query_id\"].astype(int)\n",
                "qrels[\"corpus_id\"] = qrels[\"corpus_id\"].astype(int)\n",
                "\n",
                "print(f\"Loaded {len(queries_ds)} queries and {len(qrels)} relevance judgments\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "load_corpus",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 2483 corpus documents\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "from langchain_core.documents import Document\n",
                "\n",
                "# Load corpus using simple JSON reading (no jq dependency)\n",
                "corpus_docs = []\n",
                "\n",
                "with open(dataset_dir / \"corpus.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
                "    for line in f:\n",
                "        record = json.loads(line)\n",
                "\n",
                "        # Extract text and metadata\n",
                "        text = record.get(\"text_plain\", \"\")\n",
                "        metadata = {\n",
                "            \"corpus_id\": int(record[\"doc_id\"]),\n",
                "            \"person_id\": str(record.get(\"person_id\", record.get(\"doc_id\"))),\n",
                "            \"raw_html\": (\n",
                "                record.get(\"resume_html\")\n",
                "                or record.get(\"text_html\")\n",
                "                or record.get(\"Resume_html\")\n",
                "                or record.get(\"html\")\n",
                "            ),\n",
                "        }\n",
                "\n",
                "        corpus_docs.append(Document(page_content=text, metadata=metadata))\n",
                "\n",
                "print(f\"Loaded {len(corpus_docs)} corpus documents\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "utils_section",
            "metadata": {},
            "source": [
                "## 3) HTML-Aware Splitting Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "html_splitter_class",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Optional, List as PyList\n",
                "from bs4 import BeautifulSoup\n",
                "\n",
                "try:\n",
                "    # Newer LangChain\n",
                "    from langchain_core.documents import Document\n",
                "except Exception:\n",
                "    # Older LangChain\n",
                "    from langchain_core.documents import Document\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "\n",
                "\n",
                "class HTMLSectionTextSplitter:\n",
                "    \"\"\"LangChain-compatible splitter for HTML resume sections\"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        inner_splitter: Optional[RecursiveCharacterTextSplitter] = None,\n",
                "        min_section_chars: int = 200,\n",
                "    ):\n",
                "        self.inner_splitter = inner_splitter\n",
                "        self.min_section_chars = min_section_chars\n",
                "\n",
                "    def split_documents(self, docs: PyList[Document]) -> PyList[Document]:\n",
                "        out_docs = []\n",
                "\n",
                "        for d in docs:\n",
                "            md = dict(d.metadata or {})\n",
                "            html = md.get(\"raw_html\") or d.page_content\n",
                "\n",
                "            # Simple section extraction\n",
                "            soup = BeautifulSoup(html, \"lxml\")\n",
                "            text = soup.get_text(\" \", strip=True)\n",
                "\n",
                "            if len(text) < self.min_section_chars:\n",
                "                continue\n",
                "\n",
                "            section_md = {**md, \"chunking\": \"html_section\"}\n",
                "            section_doc = Document(page_content=text, metadata=section_md)\n",
                "\n",
                "            if self.inner_splitter:\n",
                "                out_docs.extend(\n",
                "                    self.inner_splitter.split_documents([section_doc])\n",
                "                )\n",
                "            else:\n",
                "                out_docs.append(section_doc)\n",
                "\n",
                "        return out_docs\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "metrics_section",
            "metadata": {},
            "source": [
                "## 4) Retrieval Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "metrics_functions",
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "from typing import Dict, List as PyList, Set\n",
                "\n",
                "def _ndcg_at_k(ranked_ids: PyList[int], relevant_set: Set[int], k: int) -> float:\n",
                "    rels = [1 if doc_id in relevant_set else 0 for doc_id in ranked_ids[:k]]\n",
                "    dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(rels))\n",
                "\n",
                "    ideal_rels = [1] * min(k, len(relevant_set)) + [0] * max(0, k - len(relevant_set))\n",
                "    idcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(ideal_rels))\n",
                "\n",
                "    return (dcg / idcg) if idcg > 0 else 0.0\n",
                "\n",
                "def _rr(ranked_ids: PyList[int], relevant_set: Set[int]) -> float:\n",
                "    for i, doc_id in enumerate(ranked_ids):\n",
                "        if doc_id in relevant_set:\n",
                "            return 1.0 / (i + 1)\n",
                "    return 0.0\n",
                "\n",
                "def compute_metrics(\n",
                "    retrieved_docs: PyList[PyList[int]],\n",
                "    ground_truth_docs: PyList[PyList[int]],\n",
                "    ks: PyList[int] = [5, 10],\n",
                ") -> Dict[str, float]:\n",
                "    total = len(retrieved_docs)\n",
                "    if total == 0:\n",
                "        return {f\"Precision@{k}\": 0.0 for k in ks} | {f\"Recall@{k}\": 0.0 for k in ks} | {f\"NDCG@{k}\": 0.0 for k in ks} | {\"MRR\": 0.0}\n",
                "\n",
                "    sums: Dict[str, float] = {}\n",
                "    for k in ks:\n",
                "        sums[f\"Precision@{k}\"] = 0.0\n",
                "        sums[f\"Recall@{k}\"] = 0.0\n",
                "        sums[f\"NDCG@{k}\"] = 0.0\n",
                "    sums[\"MRR\"] = 0.0\n",
                "\n",
                "    for retrieved, gt in zip(retrieved_docs, ground_truth_docs):\n",
                "        rel = set(gt)\n",
                "        for k in ks:\n",
                "            topk = retrieved[:k]\n",
                "            tp = sum(1 for x in topk if x in rel)\n",
                "            precision = tp / len(topk) if topk else 0.0\n",
                "            recall = tp / len(rel) if rel else 0.0\n",
                "\n",
                "            sums[f\"Precision@{k}\"] += precision\n",
                "            sums[f\"Recall@{k}\"] += recall\n",
                "            sums[f\"NDCG@{k}\"] += _ndcg_at_k(retrieved, rel, k)\n",
                "\n",
                "        sums[\"MRR\"] += _rr(retrieved, rel)\n",
                "\n",
                "    for key in sums:\n",
                "        sums[key] /= total\n",
                "\n",
                "    return sums"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "config_section",
            "metadata": {},
            "source": [
                "## 5) Define Configurations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "config_setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total configurations: 4\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "\n",
                "SEED = 42\n",
                "random.seed(SEED)\n",
                "\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "# Splitters\n",
                "base_splitters = [\n",
                "    (\n",
                "        \"chunk256_overlap32\",\n",
                "        RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
                "            \"gpt2\", chunk_size=256, chunk_overlap=32\n",
                "        ),\n",
                "    ),\n",
                "]\n",
                "\n",
                "html_section_splitters = [\n",
                "    (\"html_sections_only\",\n",
                "     HTMLSectionTextSplitter(inner_splitter=None, min_section_chars=200)),\n",
                "\n",
                "    (\"html_sections_then_chunk128o32\",\n",
                "     HTMLSectionTextSplitter(\n",
                "         inner_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
                "             \"gpt2\", chunk_size=128, chunk_overlap=32\n",
                "         ),\n",
                "         min_section_chars=200,\n",
                "     )),\n",
                "\n",
                "    (\"html_sections_then_chunk256o32\",\n",
                "     HTMLSectionTextSplitter(\n",
                "         inner_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
                "             \"gpt2\", chunk_size=256, chunk_overlap=32\n",
                "         ),\n",
                "         min_section_chars=200,\n",
                "     )),\n",
                "]\n",
                "\n",
                "\n",
                "SPLITTERS = base_splitters + html_section_splitters\n",
                "\n",
                "# Embeddings\n",
                "EMBEDDERS = [\n",
                "    (\n",
                "        \"all-MiniLM-L6-v2\",\n",
                "        {\n",
                "            \"model_name\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "            \"model_kwargs\": {\"device\": \"cpu\"},\n",
                "            \"encode_kwargs\": {\"normalize_embeddings\": True, \"batch_size\": BATCH_SIZE},\n",
                "        },\n",
                "    ),\n",
                "]\n",
                "\n",
                "SEARCH_TYPES = [\"similarity\"]\n",
                "TOPK = [10]\n",
                "INDEX_SCHEMES = [\"faiss_flat\", \"faiss_ivf\"]\n",
                "\n",
                "print(\n",
                "    f\"Total configurations: {len(SPLITTERS) * len(EMBEDDERS) * len(SEARCH_TYPES) * len(TOPK)}\"\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eval_section",
            "metadata": {},
            "source": [
                "## 6) Build RAG Pipeline and Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "build_pipeline",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.vectorstores import FAISS\n",
                "\n",
                "def build_rag_pipeline(\n",
                "    corpus_docs,\n",
                "    splitter_obj,\n",
                "    embed_kwargs,\n",
                "    search_type,\n",
                "    k,\n",
                "    index_scheme=\"faiss_flat\",   # NEW\n",
                "    ivf_nlist=256,               # NEW (tweakable)\n",
                "):\n",
                "    \"\"\"\n",
                "    Build retriever:\n",
                "      - chunk docs\n",
                "      - embed\n",
                "      - index into FAISS with either Flat or IVF\n",
                "      - return retriever (similarity or MMR)\n",
                "    \"\"\"\n",
                "\n",
                "    # 1) chunk\n",
                "    chunked_docs = splitter_obj.split_documents(corpus_docs)\n",
                "\n",
                "    # 2) embedder\n",
                "    embeddings = HuggingFaceEmbeddings(**embed_kwargs)\n",
                "\n",
                "    # 3) build index\n",
                "    if index_scheme == \"faiss_flat\":\n",
                "        vs = FAISS.from_documents(chunked_docs, embeddings)\n",
                "\n",
                "    elif index_scheme == \"faiss_ivf\":\n",
                "        # IVF needs training; FAISS wrapper provides a helper\n",
                "        # NOTE: For small corpora IVF may be worse than flat (expected).\n",
                "        vs = FAISS.from_documents(chunked_docs, embeddings)\n",
                "        # Convert underlying index to IVF (best-effort)\n",
                "        try:\n",
                "            import faiss\n",
                "            dim = vs.index.d\n",
                "            quantizer = faiss.IndexFlatIP(dim)  # because we normalize embeddings => inner product ~ cosine\n",
                "            ivf = faiss.IndexIVFFlat(quantizer, dim, int(ivf_nlist), faiss.METRIC_INNER_PRODUCT)\n",
                "\n",
                "            # train + add vectors\n",
                "            xb = vs.index.reconstruct_n(0, vs.index.ntotal)\n",
                "            ivf.train(xb)\n",
                "            ivf.add(xb)\n",
                "\n",
                "            vs.index = ivf\n",
                "        except Exception as e:\n",
                "            raise RuntimeError(f\"Failed to build IVF index. Install faiss and ensure CPU/GPU faiss is available. Error: {e}\")\n",
                "\n",
                "    else:\n",
                "        raise ValueError(f\"Unknown index_scheme: {index_scheme}. Use 'faiss_flat' or 'faiss_ivf'.\")\n",
                "\n",
                "    # 4) retriever\n",
                "    if search_type == \"mmr\":\n",
                "        retriever = vs.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": int(k)})\n",
                "    else:\n",
                "        retriever = vs.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": int(k)})\n",
                "\n",
                "    return retriever\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "evaluate",
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_config(\n",
                "    corpus_docs,\n",
                "    splitter_name,\n",
                "    splitter_obj,\n",
                "    embed_name,\n",
                "    embed_kwargs,\n",
                "    search_type,\n",
                "    index_scheme,   # NEW\n",
                "    k,\n",
                "):\n",
                "\n",
                "    \"\"\"Evaluate a single configuration\"\"\"\n",
                "\n",
                "    config_name = f\"{splitter_name}__emb={embed_name}__{search_type}__index={index_scheme}__k={k}\"\n",
                "    print(f\"\\nEvaluating: {config_name}\")\n",
                "\n",
                "    # Build pipeline\n",
                "    retriever = build_rag_pipeline(\n",
                "    corpus_docs,\n",
                "    splitter_obj,\n",
                "    embed_kwargs,\n",
                "    search_type,\n",
                "    k,\n",
                "    index_scheme=index_scheme,   # NEW\n",
                ")\n",
                "\n",
                "    # Retrieve for all queries\n",
                "    retrieved_documents = []\n",
                "    for query in queries_ds[\"query\"]:\n",
                "        retrieved = retriever.invoke(query)  # list[Document]\n",
                "        ids = []\n",
                "        for d in retrieved:\n",
                "            if \"corpus_id\" in (d.metadata or {}):\n",
                "                ids.append(int(d.metadata[\"corpus_id\"]))\n",
                "        retrieved_documents.append(ids)\n",
                "\n",
                "    # Get ground truth\n",
                "    ground_truth_documents = [\n",
                "        qrels.loc[qrels[\"query_id\"] == int(qid), \"corpus_id\"].astype(int).tolist()\n",
                "        for qid in queries_ds[\"query_id\"]\n",
                "    ]\n",
                "\n",
                "    # Compute metrics\n",
                "    metrics = compute_metrics(retrieved_documents, ground_truth_documents)\n",
                "\n",
                "    print(f\"Results for {config_name}:\")\n",
                "    for metric_name, value in metrics.items():\n",
                "        print(f\"  {metric_name}: {value:.4f}\")\n",
                "\n",
                "    return {\"config\": config_name, \"metrics\": metrics}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "run_evaluation",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[1/8] Running: chunk256_overlap32 | all-MiniLM-L6-v2 | similarity | faiss_flat | k=10\n",
                        "\n",
                        "Evaluating: chunk256_overlap32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\jayan\\AppData\\Local\\Temp\\ipykernel_28068\\1550007412.py:24: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
                        "  embeddings = HuggingFaceEmbeddings(**embed_kwargs)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for chunk256_overlap32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10:\n",
                        "  Precision@5: 0.3467\n",
                        "  Recall@5: 0.0741\n",
                        "  NDCG@5: 0.3257\n",
                        "  Precision@10: 0.3067\n",
                        "  Recall@10: 0.1169\n",
                        "  NDCG@10: 0.3057\n",
                        "  MRR: 0.4211\n",
                        "\n",
                        "[2/8] Running: chunk256_overlap32 | all-MiniLM-L6-v2 | similarity | faiss_ivf | k=10\n",
                        "\n",
                        "Evaluating: chunk256_overlap32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10\n",
                        "Results for chunk256_overlap32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10:\n",
                        "  Precision@5: 0.2000\n",
                        "  Recall@5: 0.0268\n",
                        "  NDCG@5: 0.2100\n",
                        "  Precision@10: 0.1733\n",
                        "  Recall@10: 0.0465\n",
                        "  NDCG@10: 0.1874\n",
                        "  MRR: 0.3133\n",
                        "\n",
                        "[3/8] Running: html_sections_only | all-MiniLM-L6-v2 | similarity | faiss_flat | k=10\n",
                        "\n",
                        "Evaluating: html_sections_only__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10\n",
                        "Results for html_sections_only__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10:\n",
                        "  Precision@5: 0.3067\n",
                        "  Recall@5: 0.0502\n",
                        "  NDCG@5: 0.3183\n",
                        "  Precision@10: 0.2600\n",
                        "  Recall@10: 0.0800\n",
                        "  NDCG@10: 0.2817\n",
                        "  MRR: 0.5430\n",
                        "\n",
                        "[4/8] Running: html_sections_only | all-MiniLM-L6-v2 | similarity | faiss_ivf | k=10\n",
                        "\n",
                        "Evaluating: html_sections_only__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10\n",
                        "Results for html_sections_only__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10:\n",
                        "  Precision@5: 0.1200\n",
                        "  Recall@5: 0.0178\n",
                        "  NDCG@5: 0.1430\n",
                        "  Precision@10: 0.0867\n",
                        "  Recall@10: 0.0204\n",
                        "  NDCG@10: 0.1018\n",
                        "  MRR: 0.2241\n",
                        "\n",
                        "[5/8] Running: html_sections_then_chunk128o32 | all-MiniLM-L6-v2 | similarity | faiss_flat | k=10\n",
                        "\n",
                        "Evaluating: html_sections_then_chunk128o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10\n",
                        "Results for html_sections_then_chunk128o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10:\n",
                        "  Precision@5: 0.3867\n",
                        "  Recall@5: 0.0695\n",
                        "  NDCG@5: 0.3812\n",
                        "  Precision@10: 0.3400\n",
                        "  Recall@10: 0.1308\n",
                        "  NDCG@10: 0.3491\n",
                        "  MRR: 0.5711\n",
                        "\n",
                        "[6/8] Running: html_sections_then_chunk128o32 | all-MiniLM-L6-v2 | similarity | faiss_ivf | k=10\n",
                        "\n",
                        "Evaluating: html_sections_then_chunk128o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10\n",
                        "Results for html_sections_then_chunk128o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10:\n",
                        "  Precision@5: 0.2133\n",
                        "  Recall@5: 0.0315\n",
                        "  NDCG@5: 0.1890\n",
                        "  Precision@10: 0.1867\n",
                        "  Recall@10: 0.0478\n",
                        "  NDCG@10: 0.1803\n",
                        "  MRR: 0.2606\n",
                        "\n",
                        "[7/8] Running: html_sections_then_chunk256o32 | all-MiniLM-L6-v2 | similarity | faiss_flat | k=10\n",
                        "\n",
                        "Evaluating: html_sections_then_chunk256o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10\n",
                        "Results for html_sections_then_chunk256o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10:\n",
                        "  Precision@5: 0.3467\n",
                        "  Recall@5: 0.0741\n",
                        "  NDCG@5: 0.3257\n",
                        "  Precision@10: 0.3067\n",
                        "  Recall@10: 0.1169\n",
                        "  NDCG@10: 0.3057\n",
                        "  MRR: 0.4211\n",
                        "\n",
                        "[8/8] Running: html_sections_then_chunk256o32 | all-MiniLM-L6-v2 | similarity | faiss_ivf | k=10\n",
                        "\n",
                        "Evaluating: html_sections_then_chunk256o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10\n",
                        "Results for html_sections_then_chunk256o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10:\n",
                        "  Precision@5: 0.2000\n",
                        "  Recall@5: 0.0268\n",
                        "  NDCG@5: 0.2100\n",
                        "  Precision@10: 0.1733\n",
                        "  Recall@10: 0.0465\n",
                        "  NDCG@10: 0.1874\n",
                        "  MRR: 0.3133\n",
                        "\n",
                        "============================================================\n",
                        "Completed 8 evaluations\n"
                    ]
                }
            ],
            "source": [
                "# Run evaluations\n",
                "results = []\n",
                "\n",
                "total_runs = (\n",
                "    len(SPLITTERS) * len(EMBEDDERS) * len(SEARCH_TYPES) * len(INDEX_SCHEMES) * len(TOPK)\n",
                ")\n",
                "run_i = 0\n",
                "\n",
                "for splitter_name, splitter_obj in SPLITTERS:\n",
                "    for embed_name, embed_kwargs in EMBEDDERS:\n",
                "        for stype in SEARCH_TYPES:\n",
                "            for index_scheme in INDEX_SCHEMES:\n",
                "                for k in TOPK:\n",
                "                    run_i += 1\n",
                "                    print(f\"\\n[{run_i}/{total_runs}] Running: \"\n",
                "                          f\"{splitter_name} | {embed_name} | {stype} | {index_scheme} | k={k}\")\n",
                "\n",
                "                    result = evaluate_config(\n",
                "                        corpus_docs=corpus_docs,\n",
                "                        splitter_name=splitter_name,\n",
                "                        splitter_obj=splitter_obj,\n",
                "                        embed_name=embed_name,\n",
                "                        embed_kwargs=embed_kwargs,\n",
                "                        search_type=stype,\n",
                "                        index_scheme=index_scheme,\n",
                "                        k=k,\n",
                "                    )\n",
                "                    results.append(result)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(f\"Completed {len(results)} evaluations\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "results_section",
            "metadata": {},
            "source": [
                "## 7) Summary of Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "display_results",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Final Results (sorted):\n",
                        "                                                                           Configuration  Precision@5  Recall@5  NDCG@5  Precision@10  Recall@10  NDCG@10    MRR\n",
                        "html_sections_then_chunk128o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10       0.3867    0.0695  0.3812        0.3400     0.1308   0.3491 0.5711\n",
                        "            chunk256_overlap32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10       0.3467    0.0741  0.3257        0.3067     0.1169   0.3057 0.4211\n",
                        "html_sections_then_chunk256o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10       0.3467    0.0741  0.3257        0.3067     0.1169   0.3057 0.4211\n",
                        "            html_sections_only__emb=all-MiniLM-L6-v2__similarity__index=faiss_flat__k=10       0.3067    0.0502  0.3183        0.2600     0.0800   0.2817 0.5430\n",
                        " html_sections_then_chunk256o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10       0.2000    0.0268  0.2100        0.1733     0.0465   0.1874 0.3133\n",
                        "             chunk256_overlap32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10       0.2000    0.0268  0.2100        0.1733     0.0465   0.1874 0.3133\n",
                        " html_sections_then_chunk128o32__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10       0.2133    0.0315  0.1890        0.1867     0.0478   0.1803 0.2606\n",
                        "             html_sections_only__emb=all-MiniLM-L6-v2__similarity__index=faiss_ivf__k=10       0.1200    0.0178  0.1430        0.0867     0.0204   0.1018 0.2241\n",
                        "\n",
                        "Saved: retrieval_sweep_results.csv\n"
                    ]
                }
            ],
            "source": [
                "# Display results as DataFrame (sorted + clean)\n",
                "results_data = []\n",
                "for r in results:\n",
                "    row = {\"Configuration\": r[\"config\"]}\n",
                "    row.update(r[\"metrics\"])   # metrics are already scalars\n",
                "    results_data.append(row)\n",
                "\n",
                "results_df = pd.DataFrame(results_data)\n",
                "\n",
                "# Choose sort metric (change if you prefer another)\n",
                "sort_metric = \"NDCG@10\" if \"NDCG@10\" in results_df.columns else (\n",
                "    \"NDCG@5\" if \"NDCG@5\" in results_df.columns else None\n",
                ")\n",
                "if sort_metric:\n",
                "    results_df = results_df.sort_values(by=sort_metric, ascending=False)\n",
                "\n",
                "# Optional: round numeric columns for readability\n",
                "num_cols = results_df.select_dtypes(include=\"number\").columns\n",
                "results_df[num_cols] = results_df[num_cols].round(4)\n",
                "\n",
                "print(\"\\nFinal Results (sorted):\")\n",
                "print(results_df.to_string(index=False))\n",
                "\n",
                "# Optional: save to CSV so you can reuse it in your notebook / summary doc\n",
                "results_df.to_csv(\"retrieval_sweep_results.csv\", index=False)\n",
                "print(\"\\nSaved: retrieval_sweep_results.csv\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b011494",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
